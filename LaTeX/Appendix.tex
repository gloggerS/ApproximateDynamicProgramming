\chapter{Mathematical Theory and Proofs}

\begin{lemma}\label{l-expSmooth}
	If the optimal solution of the policy iteration optimization model as presented in \Crefrange{opt-updateParam-beginning}{opt-updateParam-end} is unique for each policy iteration $k$, then exponential smoothing results in the same return variable as using the optimal updates in each iteration and returning the overall average in the end. Exponential smoothing was presented in Equations \eqref{expSM-1} and \eqref{expSM-2} and is shown again without the $t$ index for convenience.
	\begin{align}
	\theta^{k+1} &= \left(1- \frac{1}{k} \right)	\theta^k + \frac{1}{k} \theta^{update,k}\\
	\boldsymbol{\pi}^{k+1} &= \left(1- \frac{1}{k} \right)	\boldsymbol{\pi}^k + \frac{1}{k} \boldsymbol{\pi}^{update,k}
	\end{align}
	The other procedure of using the updates directly was presented in \Crefrange{dir-1}{dir-2} and is also shown again.
	\begin{align}
	\theta^{k+1} &= \theta^{update,k}\\
	\boldsymbol{\pi}^{k+1} &= \boldsymbol{\pi}^{update,k}
	\end{align}
\end{lemma}

\begin{proof}
	Without loss of generality (w.\,l.\,o.\,g.), it suffices to show the statement just for $\theta$. We have to show that the iterative exponential smoothing results in the same value as taking the average in the very end. We proof this by induction over the total number of policy iterations $K$. The statement trivially holds for $K=1$. So let the statement hold for $K=n$, i.e.
	$$\theta^{n+1} = \left(1- \frac{1}{n} \right)	\theta^n + \frac{1}{n} \theta^{update,n} = \frac{1}{n}\sum_{i=1}^{n} \theta^{update,i}~.$$
	Now, we apply one more step of exponential smoothing, use the induction hypothesis and summation rules to derive our hypothesis and proof \Cref{l-expSmooth}.
	\begin{align}
	\theta^{n+2} &= \left(1- \frac{1}{n+1} \right)	\theta^{n+1} + \frac{1}{n+1} \theta^{update,n+1}\\
	&= \left(1- \frac{1}{n+1} \right) \left( \frac{1}{n}\sum_{i=1}^{n} \theta^{update,i} \right) + \frac{1}{n+1} \theta^{update,n+1}\\
	&= \frac{n}{n+1}\frac{1}{n}\sum_{i=1}^{n} \theta^{update,i} + \frac{1}{n+1} \theta^{update,n+1}\\
	&= \frac{1}{n+1}\sum_{i=1}^{n} \theta^{update,i} + \frac{1}{n+1} \theta^{update,n+1}\\
	&= \frac{1}{n+1}\sum_{i=1}^{n+1} \theta^{update,i}
	\end{align}
\end{proof}

\begin{remark}
	Note that the optimization problem depends on the current values of the optimization variables as these are used in the sample run to determine the offersets and ultimately affect the sample value function $\hat{V}_t^i$. So theoretically that there is no (obvious) reason why \Cref{l-expSmooth} shall be applicable. But in my experiments it made no difference, whether exponential smoothing was applied directly or the average taken in the end. The results in this thesis were generated by using exponential smoothing.
\end{remark}

\chapter{Data Scientist}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth]{certificate-DataScientist.pdf}
	\caption[Certificate \enquote{Data Scientist with Python Track}]{Certificate \enquote{Data Scientist with Python Track} with $100$ learning hours.}
\end{figure}

This career track on \href{https://www.datacamp.com/tracks/data-scientist-with-python}{DataCamp} helped me to improve my Python coding skills and apply analytical techniques in Python. It comprised the courses:

\begin{multicols}{2}
	\scriptsize
	\begin{enumerate}[noitemsep]
		\item Introduction to Python
		\item Intermediate Python for Data Science
		\item Python Data Science Toolbox (Part 1)
		\item Python Data Science Toolbox (Part 2)
		\item Importing Data in Python (Part 1)
		\item Importing Data in Python (Part 2)
		\item Cleaning Data in Python
		\item pandas Foundations
		\item Manipulating DataFrames with pandas
		\item Merging DataFrames with pandas
		\item Analyzing Police Activity with pandas
		\item Intro to SQL for Data Science
		\item Introduction to Relational Databases in SQL
		\item Introduction to Data Visualization with Python
		\item Interactive Data Visualization with Bokeh
		\item Statistical Thinking in Python (Part 1)
		\item Statistical Thinking in Python (Part 2)
		\item Joining Data in SQL
		\item Introduction to Shell for Data Science
		\item Conda Essentials
		\item Supervised Learning with scikit-learn
		\item Machine Learning with the Experts: School Budgets
		\item Unsupervised Learning in Python
		\item Machine Learning with Tree-Based Models in Python
		\item Deep Learning in Python
		\item Network Analysis in Python (Part 1) 
	\end{enumerate}
\end{multicols}